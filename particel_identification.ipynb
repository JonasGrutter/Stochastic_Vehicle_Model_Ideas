{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "\n",
    "from models.model2 import BicycleModel\n",
    "from models.model4 import FourWheelModel\n",
    "from models.utils import get_csv_row_count\n",
    "from models.utils import get_folder_path\n",
    "from models.utils import fit_circle\n",
    "from models.utils import plot_column_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "Iteration:  26\n",
      "Iteration:  27\n",
      "Iteration:  28\n",
      "Iteration:  29\n",
      "Iteration:  30\n",
      "Iteration:  31\n",
      "Iteration:  32\n",
      "Iteration:  33\n",
      "Iteration:  34\n",
      "Iteration:  35\n",
      "Iteration:  36\n",
      "Iteration:  37\n",
      "Iteration:  38\n",
      "Iteration:  39\n",
      "Iteration:  40\n",
      "Iteration:  41\n",
      "Iteration:  42\n",
      "Iteration:  43\n",
      "Iteration:  44\n",
      "Iteration:  45\n",
      "Iteration:  46\n",
      "Iteration:  47\n",
      "Iteration:  48\n",
      "Iteration:  49\n",
      "Iteration:  50\n",
      "Iteration:  51\n",
      "Iteration:  52\n",
      "Iteration:  53\n",
      "Iteration:  54\n",
      "Iteration:  55\n",
      "Iteration:  56\n",
      "Iteration:  57\n",
      "Iteration:  58\n",
      "Iteration:  59\n",
      "Iteration:  60\n",
      "Iteration:  61\n",
      "Iteration:  62\n",
      "Iteration:  63\n",
      "Iteration:  64\n",
      "Iteration:  65\n",
      "Iteration:  66\n",
      "Iteration:  67\n",
      "Iteration:  68\n",
      "Iteration:  69\n",
      "Iteration:  70\n",
      "Iteration:  71\n",
      "Iteration:  72\n",
      "Iteration:  73\n",
      "Iteration:  74\n",
      "Iteration:  75\n",
      "Iteration:  76\n",
      "Iteration:  77\n",
      "Iteration:  78\n",
      "Iteration:  79\n",
      "Iteration:  80\n",
      "Iteration:  81\n",
      "Iteration:  82\n",
      "Iteration:  83\n",
      "Iteration:  84\n",
      "Iteration:  85\n",
      "Iteration:  86\n",
      "Iteration:  87\n",
      "Iteration:  88\n",
      "Iteration:  89\n",
      "Iteration:  90\n",
      "Iteration:  91\n",
      "Iteration:  92\n",
      "Iteration:  93\n",
      "Iteration:  94\n",
      "Iteration:  95\n",
      "Iteration:  96\n",
      "Iteration:  97\n",
      "Iteration:  98\n",
      "Iteration:  99\n",
      "Iteration:  100\n",
      "Iteration:  101\n",
      "Iteration:  102\n",
      "Iteration:  103\n",
      "Iteration:  104\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonas/Desktop/intergation_model/particel_identification.ipynb Cell 2\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39m# Run the inference\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m num_iterations \u001b[39m=\u001b[39m \u001b[39m150\u001b[39m  \u001b[39m# Number of iterations\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m particles \u001b[39m=\u001b[39m particle_method\u001b[39m.\u001b[39;49mrun_inference(num_iterations)\n",
      "\u001b[1;32m/Users/jonas/Desktop/intergation_model/particel_identification.ipynb Cell 2\u001b[0m in \u001b[0;36mParticleBasedMethod.run_inference\u001b[0;34m(self, num_iterations)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iterations):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_particles()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresample_particles()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mIteration: \u001b[39m\u001b[39m'\u001b[39m,i)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparticles\n",
      "\u001b[1;32m/Users/jonas/Desktop/intergation_model/particel_identification.ipynb Cell 2\u001b[0m in \u001b[0;36mParticleBasedMethod.resample_particles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresample_particles\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(\u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_particles), size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_particles, replace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, p\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparticles \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparticles[indices]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonas/Desktop/intergation_model/particel_identification.ipynb#W0sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n",
      "File \u001b[0;32mmtrand.pyx:935\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class ParticleBasedMethod:\n",
    "    def __init__(self, num_particles):\n",
    "        self.num_particles = num_particles\n",
    "        self.list_of_param = ['T_peak', 'T_slope']\n",
    "        self.param_to_infer = len(self.list_of_param)\n",
    "        self.variances_to_infer = 1\n",
    "\n",
    "        self.prior_mean = 0.5\n",
    "        self.prior_stddev = 0.1\n",
    "\n",
    "\n",
    "        self.particles = None\n",
    "        self.weights = None\n",
    "        self.initialize_particles()\n",
    "\n",
    "        self.total_particles = self.particles\n",
    "\n",
    "\n",
    "                # Current model and model parameters\n",
    "        self.model = None\n",
    "        self.dt = 0.025\n",
    "        self.commands = get_folder_path()+'/open_loop_inputs/open_loop_commands.csv'\n",
    "        self.N = get_csv_row_count(self.commands)\n",
    "        self.open_loop_tf = self.N*self.dt\n",
    "        # T_peak and T_slope is not specified since we infer those\n",
    "        self.x_vect_ref = self.get_x_vect_ref()\n",
    "        self.y_likelihood = 0\n",
    "\n",
    "\n",
    "\n",
    "    def initialize_particles(self):\n",
    "        self.particles = np.zeros((self.num_particles, self.param_to_infer+self.variances_to_infer))\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "        for i in range(self.num_particles):\n",
    "            new = self.prior_sampler()\n",
    "            for j in range(self.particles[i].size):\n",
    "                self.particles[i][j] = new[j]\n",
    "\n",
    "    def update_particles(self):\n",
    "        for i in range(self.num_particles):\n",
    "            self.particles[i] = self.proposal_sampler(self.particles[i])\n",
    "            #print( 'Likelihood:', self.likelihood_evaluator(self.particles[i]))\n",
    "            self.weights[i] *= self.likelihood_evaluator(self.particles[i])\n",
    "        for i in range(self.weights):\n",
    "            \n",
    "        self.weights /= np.sum(self.weights)\n",
    "        #print('Weights: ', self.weights)\n",
    "\n",
    "    def resample_particles(self):\n",
    "        indices = np.random.choice(range(self.num_particles), size=self.num_particles, replace=True, p=self.weights) \n",
    "        self.particles = self.particles[indices]\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "\n",
    "\n",
    "    # Define the prior distribution sampler\n",
    "    def prior_sampler(self):\n",
    "        # Implement your own prior distribution sampling logic\n",
    "        # Return a sample from the prior distribution                \n",
    "        sample = np.random.normal(self.prior_mean, self.prior_stddev, size= self.param_to_infer+self.variances_to_infer)\n",
    "        return sample\n",
    "\n",
    "    # Define the proposal distribution sampler\n",
    "    def proposal_sampler(self, particle):\n",
    "        proposal_mean = particle  # Use the current particle as the mean for the proposal distribution\n",
    "        proposal_stddev = 0.1  # Choose an appropriate standard deviation for the proposal distribution\n",
    "        sample = np.random.normal(proposal_mean, proposal_stddev, size=len(particle))\n",
    "        return sample\n",
    "\n",
    "    # Define the likelihood evaluator\n",
    "    def likelihood_evaluator(self, particle):\n",
    "        \n",
    "        # Given the observed data and a particle, compute the likelihood\n",
    "        predicted_kpi = self.get_kpi(particle)  # Replace `model_simulation` with your own function that generates predicted data\n",
    "        # Compute the likelihood using a probability distribution or a statistical measure\n",
    "        if self.variances_to_infer == 1:\n",
    "            log_likelihood_vect = sc.norm.logpdf(self.y_likelihood, loc= predicted_kpi, scale=particle[self.param_to_infer]) # Loc will be simulation(theta(:param_to_infer), scale = theta[param_to_infer])\n",
    "            #print('log_likelihood_vect', log_likelihood_vect)\n",
    "        else:\n",
    "            mean_vector = np.full(self.param_to_infer, predicted_kpi)\n",
    "            log_likelihood_vect = sc.multivariate_normal.logpdf(self.y_likelihood, mean= mean_vector, cov=np.diag(particle[self.param_to_infer:])) # Loc will be simulation(theta(:param_to_infer), scale = theta[param_to_infer])\n",
    "        log_likelihood_out = np.sum(log_likelihood_vect)\n",
    "\n",
    "        likelihood = np.exp(log_likelihood_out)\n",
    "        \n",
    "        return likelihood\n",
    "\n",
    "\n",
    "    \n",
    "    #--------------- Open loop simulation ---------------#\n",
    "\n",
    "    def generate_new_model(self, Tetha):\n",
    "        T_peak = Tetha[0]\n",
    "        T_slope = Tetha[1]\n",
    "        self.model = FourWheelModel( self.dt, self.open_loop_tf,float(T_peak), float(T_slope))\n",
    "    \n",
    "    def get_kpi(self, particle):\n",
    "        self.generate_new_model(particle[:self.param_to_infer])\n",
    "        \n",
    "        t,x_vect = self.get_open_loop_data()\n",
    "        \n",
    "        l2_norm_position = np.linalg.norm(self.x_vect_ref[:,:2] - x_vect[:,:2], axis=1).sum()\n",
    "        l2_norm_velocity = np.linalg.norm(self.x_vect_ref[:,2:] - x_vect[:,2:], axis=1).sum()\n",
    "\n",
    "        w1 = 0.00005\n",
    "        w2 = 0.00005\n",
    "        kpi = w1*l2_norm_position+w2*l2_norm_velocity\n",
    "        return kpi\n",
    "\n",
    "\n",
    "    def get_open_loop_data(self):\n",
    "        \n",
    "        t,x_vect = self.model.do_open_loop_sim_from_csv(self.commands)\n",
    "        \n",
    "        return t,x_vect\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_x_vect_ref(self):\n",
    "        T_peak_ref = 0.37\n",
    "        T_slope_ref = 0.4\n",
    "        self.model = FourWheelModel(self.dt,self.open_loop_tf, T_peak_ref, T_slope_ref)\n",
    "        t,x = self.get_open_loop_data()\n",
    "        return x\n",
    "\n",
    "\n",
    "    #\n",
    "    def run_inference(self, num_iterations):\n",
    "        for i in range(num_iterations):\n",
    "            self.update_particles()\n",
    "            self.resample_particles()\n",
    "\n",
    "            print('Iteration: ',i)\n",
    "\n",
    "        return self.particles\n",
    "    \n",
    "        \n",
    "\n",
    "# Instantiate the particle-based method\n",
    "num_particles = 20  # Number of particles to use\n",
    "particle_method = ParticleBasedMethod(num_particles)\n",
    "\n",
    "# Run the inference\n",
    "num_iterations = 150  # Number of iterations\n",
    "particles = particle_method.run_inference(num_iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52467911,  0.59336553,  1.19187719],\n",
       "       [ 0.4416403 ,  0.21531031,  0.60483516],\n",
       "       [ 0.23652595,  1.3779604 ,  0.76577217],\n",
       "       [ 0.2017965 ,  0.63669423,  0.6336348 ],\n",
       "       [ 0.50914222,  0.36589511,  0.83957029],\n",
       "       [ 0.52409109,  0.21194425,  0.98195148],\n",
       "       [ 0.51599686,  0.48764474,  0.86500224],\n",
       "       [ 0.50239275,  0.60998877,  0.38745247],\n",
       "       [ 0.54548736,  0.37976831,  0.79728799],\n",
       "       [ 0.5328461 ,  0.57422213,  0.66613392],\n",
       "       [ 0.37658382,  0.27530328,  0.78388226],\n",
       "       [ 0.76017233, -0.05367715,  0.96297044],\n",
       "       [ 0.28903256,  0.53615125,  0.58794414],\n",
       "       [ 0.14026249,  0.21947154,  0.75995998],\n",
       "       [ 0.53834963,  0.41013575,  1.18661378],\n",
       "       [ 0.30804951,  0.45380694,  0.57145236],\n",
       "       [ 0.28130621,  0.44703435,  0.92295298],\n",
       "       [ 0.43317666,  0.39592901,  0.52589695],\n",
       "       [ 0.19725247,  0.54489557,  0.7958609 ],\n",
       "       [ 0.56630437,  0.3175405 ,  0.93060219]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particle_method.particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
